{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "###############################################   LAB 5   ##############################################\n",
    "################### Script written by Dr Alex Ter-Sarkisov@City, University of London, 2021 ############\n",
    "##################### DEEP LEARNING FOR IMAGE ANALYSIS, MSC IN ARTIFICIAL INTELLIGENCE #################\n",
    "########################################################################################################\n",
    "import time\n",
    "import os, sys, re\n",
    "from pycocotools.coco import COCO\n",
    "import torch\n",
    "import torchvision\n",
    "import dataset_coco\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device('cuda')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=16.43s)\n",
      "creating index...\n",
      "index created!\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90] 81\n",
      "ADJUSTED CLASS IDS:\n",
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 27: 25, 28: 26, 31: 27, 32: 28, 33: 29, 34: 30, 35: 31, 36: 32, 37: 33, 38: 34, 39: 35, 40: 36, 41: 37, 42: 38, 43: 39, 44: 40, 46: 41, 47: 42, 48: 43, 49: 44, 50: 45, 51: 46, 52: 47, 53: 48, 54: 49, 55: 50, 56: 51, 57: 52, 58: 53, 59: 54, 60: 55, 61: 56, 62: 57, 63: 58, 64: 59, 65: 60, 67: 61, 70: 62, 72: 63, 73: 64, 74: 65, 75: 66, 76: 67, 77: 68, 78: 69, 79: 70, 80: 71, 81: 72, 82: 73, 84: 74, 85: 75, 86: 76, 87: 77, 88: 78, 89: 79, 90: 80}\n"
     ]
    }
   ],
   "source": [
    "###################### load COCO interface, the input is a json file with annotations ####################\n",
    "coco_interface = COCO(\"mscoco/annotations/instances_train2017.json\")\n",
    "# all indices of categories in MS COCO:\n",
    "all_cats = coco_interface.getCatIds()\n",
    "# add background class\n",
    "all_cats.insert(0,0)\n",
    "print(all_cats, len(all_cats))\n",
    "# get names of cateogories\n",
    "all_names = coco_interface.loadCats(all_cats[1:])\n",
    "#print(all_names)\n",
    "# choose the categories you want to work with\n",
    "# VERY CAREFUL WITH THIS LIST! SOME CLASSES ARE MISSING, TO TRAIN THE MODEL\n",
    "# YOU NEED TO ADJUST THE CLASS ID!!!\n",
    "selected_class_ids = coco_interface.getCatIds(catNms=['toothbrush'])\n",
    "adjusted_class_ids = {}\n",
    "for id, cl in enumerate(all_cats):\n",
    "    adjusted_class_ids[cl] = id\n",
    "print (\"ADJUSTED CLASS IDS:\")\n",
    "print(adjusted_class_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# load ids of images with this class\n",
    "# Dataset class takes this list as an input and creates data objects \n",
    "im_ids = coco_interface.getImgIds(catIds=selected_class_ids)\n",
    "####################################################################\n",
    "# selected class ids: extract class id from the annotation\n",
    "coco_data_args = {'datalist':im_ids, 'coco_interface':coco_interface, 'coco_classes_idx':selected_class_ids,'stage':'train', 'adjusted_classes_idx':adjusted_class_ids}\n",
    "coco_data = dataset_coco.COCOData(**coco_data_args)\n",
    "coco_dataloader_args = {'batch_size':1, 'shuffle':True}\n",
    "coco_dataloader = data.DataLoader(coco_data, **coco_dataloader_args)\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskRCNN(\n",
      "  (transform): GeneralizedRCNNTransform()\n",
      "  (backbone): BackboneWithFPN(\n",
      "    (body): IntermediateLayerGetter(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): FrozenBatchNorm2d()\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): FrozenBatchNorm2d()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): FrozenBatchNorm2d()\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): FrozenBatchNorm2d()\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): FrozenBatchNorm2d()\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): FrozenBatchNorm2d()\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fpn): FeaturePyramidNetwork(\n",
      "      (inner_blocks): ModuleList(\n",
      "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (layer_blocks): ModuleList(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (extra_blocks): LastLevelMaxPool()\n",
      "    )\n",
      "  )\n",
      "  (rpn): RegionProposalNetwork(\n",
      "    (anchor_generator): AnchorGenerator()\n",
      "    (head): RPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): RoIHeads(\n",
      "    (box_roi_pool): MultiScaleRoIAlign()\n",
      "    (box_head): TwoMLPHead(\n",
      "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNPredictor(\n",
      "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=324, bias=True)\n",
      "    )\n",
      "    (mask_roi_pool): MultiScaleRoIAlign()\n",
      "    (mask_head): MaskRCNNHeads(\n",
      "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu3): ReLU(inplace=True)\n",
      "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (relu4): ReLU(inplace=True)\n",
      "    )\n",
      "    (mask_predictor): MaskRCNNPredictor(\n",
      "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (mask_fcn_logits): Conv2d(256, 81, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "backbone.body.conv1.weight\n",
      "backbone.body.bn1.weight\n",
      "backbone.body.bn1.bias\n",
      "backbone.body.bn1.running_mean\n",
      "backbone.body.bn1.running_var\n",
      "backbone.body.layer1.0.conv1.weight\n",
      "backbone.body.layer1.0.bn1.weight\n",
      "backbone.body.layer1.0.bn1.bias\n",
      "backbone.body.layer1.0.bn1.running_mean\n",
      "backbone.body.layer1.0.bn1.running_var\n",
      "backbone.body.layer1.0.conv2.weight\n",
      "backbone.body.layer1.0.bn2.weight\n",
      "backbone.body.layer1.0.bn2.bias\n",
      "backbone.body.layer1.0.bn2.running_mean\n",
      "backbone.body.layer1.0.bn2.running_var\n",
      "backbone.body.layer1.0.conv3.weight\n",
      "backbone.body.layer1.0.bn3.weight\n",
      "backbone.body.layer1.0.bn3.bias\n",
      "backbone.body.layer1.0.bn3.running_mean\n",
      "backbone.body.layer1.0.bn3.running_var\n",
      "backbone.body.layer1.0.downsample.0.weight\n",
      "backbone.body.layer1.0.downsample.1.weight\n",
      "backbone.body.layer1.0.downsample.1.bias\n",
      "backbone.body.layer1.0.downsample.1.running_mean\n",
      "backbone.body.layer1.0.downsample.1.running_var\n",
      "backbone.body.layer1.1.conv1.weight\n",
      "backbone.body.layer1.1.bn1.weight\n",
      "backbone.body.layer1.1.bn1.bias\n",
      "backbone.body.layer1.1.bn1.running_mean\n",
      "backbone.body.layer1.1.bn1.running_var\n",
      "backbone.body.layer1.1.conv2.weight\n",
      "backbone.body.layer1.1.bn2.weight\n",
      "backbone.body.layer1.1.bn2.bias\n",
      "backbone.body.layer1.1.bn2.running_mean\n",
      "backbone.body.layer1.1.bn2.running_var\n",
      "backbone.body.layer1.1.conv3.weight\n",
      "backbone.body.layer1.1.bn3.weight\n",
      "backbone.body.layer1.1.bn3.bias\n",
      "backbone.body.layer1.1.bn3.running_mean\n",
      "backbone.body.layer1.1.bn3.running_var\n",
      "backbone.body.layer1.2.conv1.weight\n",
      "backbone.body.layer1.2.bn1.weight\n",
      "backbone.body.layer1.2.bn1.bias\n",
      "backbone.body.layer1.2.bn1.running_mean\n",
      "backbone.body.layer1.2.bn1.running_var\n",
      "backbone.body.layer1.2.conv2.weight\n",
      "backbone.body.layer1.2.bn2.weight\n",
      "backbone.body.layer1.2.bn2.bias\n",
      "backbone.body.layer1.2.bn2.running_mean\n",
      "backbone.body.layer1.2.bn2.running_var\n",
      "backbone.body.layer1.2.conv3.weight\n",
      "backbone.body.layer1.2.bn3.weight\n",
      "backbone.body.layer1.2.bn3.bias\n",
      "backbone.body.layer1.2.bn3.running_mean\n",
      "backbone.body.layer1.2.bn3.running_var\n",
      "backbone.body.layer2.0.conv1.weight\n",
      "backbone.body.layer2.0.bn1.weight\n",
      "backbone.body.layer2.0.bn1.bias\n",
      "backbone.body.layer2.0.bn1.running_mean\n",
      "backbone.body.layer2.0.bn1.running_var\n",
      "backbone.body.layer2.0.conv2.weight\n",
      "backbone.body.layer2.0.bn2.weight\n",
      "backbone.body.layer2.0.bn2.bias\n",
      "backbone.body.layer2.0.bn2.running_mean\n",
      "backbone.body.layer2.0.bn2.running_var\n",
      "backbone.body.layer2.0.conv3.weight\n",
      "backbone.body.layer2.0.bn3.weight\n",
      "backbone.body.layer2.0.bn3.bias\n",
      "backbone.body.layer2.0.bn3.running_mean\n",
      "backbone.body.layer2.0.bn3.running_var\n",
      "backbone.body.layer2.0.downsample.0.weight\n",
      "backbone.body.layer2.0.downsample.1.weight\n",
      "backbone.body.layer2.0.downsample.1.bias\n",
      "backbone.body.layer2.0.downsample.1.running_mean\n",
      "backbone.body.layer2.0.downsample.1.running_var\n",
      "backbone.body.layer2.1.conv1.weight\n",
      "backbone.body.layer2.1.bn1.weight\n",
      "backbone.body.layer2.1.bn1.bias\n",
      "backbone.body.layer2.1.bn1.running_mean\n",
      "backbone.body.layer2.1.bn1.running_var\n",
      "backbone.body.layer2.1.conv2.weight\n",
      "backbone.body.layer2.1.bn2.weight\n",
      "backbone.body.layer2.1.bn2.bias\n",
      "backbone.body.layer2.1.bn2.running_mean\n",
      "backbone.body.layer2.1.bn2.running_var\n",
      "backbone.body.layer2.1.conv3.weight\n",
      "backbone.body.layer2.1.bn3.weight\n",
      "backbone.body.layer2.1.bn3.bias\n",
      "backbone.body.layer2.1.bn3.running_mean\n",
      "backbone.body.layer2.1.bn3.running_var\n",
      "backbone.body.layer2.2.conv1.weight\n",
      "backbone.body.layer2.2.bn1.weight\n",
      "backbone.body.layer2.2.bn1.bias\n",
      "backbone.body.layer2.2.bn1.running_mean\n",
      "backbone.body.layer2.2.bn1.running_var\n",
      "backbone.body.layer2.2.conv2.weight\n",
      "backbone.body.layer2.2.bn2.weight\n",
      "backbone.body.layer2.2.bn2.bias\n",
      "backbone.body.layer2.2.bn2.running_mean\n",
      "backbone.body.layer2.2.bn2.running_var\n",
      "backbone.body.layer2.2.conv3.weight\n",
      "backbone.body.layer2.2.bn3.weight\n",
      "backbone.body.layer2.2.bn3.bias\n",
      "backbone.body.layer2.2.bn3.running_mean\n",
      "backbone.body.layer2.2.bn3.running_var\n",
      "backbone.body.layer2.3.conv1.weight\n",
      "backbone.body.layer2.3.bn1.weight\n",
      "backbone.body.layer2.3.bn1.bias\n",
      "backbone.body.layer2.3.bn1.running_mean\n",
      "backbone.body.layer2.3.bn1.running_var\n",
      "backbone.body.layer2.3.conv2.weight\n",
      "backbone.body.layer2.3.bn2.weight\n",
      "backbone.body.layer2.3.bn2.bias\n",
      "backbone.body.layer2.3.bn2.running_mean\n",
      "backbone.body.layer2.3.bn2.running_var\n",
      "backbone.body.layer2.3.conv3.weight\n",
      "backbone.body.layer2.3.bn3.weight\n",
      "backbone.body.layer2.3.bn3.bias\n",
      "backbone.body.layer2.3.bn3.running_mean\n",
      "backbone.body.layer2.3.bn3.running_var\n",
      "backbone.body.layer3.0.conv1.weight\n",
      "backbone.body.layer3.0.bn1.weight\n",
      "backbone.body.layer3.0.bn1.bias\n",
      "backbone.body.layer3.0.bn1.running_mean\n",
      "backbone.body.layer3.0.bn1.running_var\n",
      "backbone.body.layer3.0.conv2.weight\n",
      "backbone.body.layer3.0.bn2.weight\n",
      "backbone.body.layer3.0.bn2.bias\n",
      "backbone.body.layer3.0.bn2.running_mean\n",
      "backbone.body.layer3.0.bn2.running_var\n",
      "backbone.body.layer3.0.conv3.weight\n",
      "backbone.body.layer3.0.bn3.weight\n",
      "backbone.body.layer3.0.bn3.bias\n",
      "backbone.body.layer3.0.bn3.running_mean\n",
      "backbone.body.layer3.0.bn3.running_var\n",
      "backbone.body.layer3.0.downsample.0.weight\n",
      "backbone.body.layer3.0.downsample.1.weight\n",
      "backbone.body.layer3.0.downsample.1.bias\n",
      "backbone.body.layer3.0.downsample.1.running_mean\n",
      "backbone.body.layer3.0.downsample.1.running_var\n",
      "backbone.body.layer3.1.conv1.weight\n",
      "backbone.body.layer3.1.bn1.weight\n",
      "backbone.body.layer3.1.bn1.bias\n",
      "backbone.body.layer3.1.bn1.running_mean\n",
      "backbone.body.layer3.1.bn1.running_var\n",
      "backbone.body.layer3.1.conv2.weight\n",
      "backbone.body.layer3.1.bn2.weight\n",
      "backbone.body.layer3.1.bn2.bias\n",
      "backbone.body.layer3.1.bn2.running_mean\n",
      "backbone.body.layer3.1.bn2.running_var\n",
      "backbone.body.layer3.1.conv3.weight\n",
      "backbone.body.layer3.1.bn3.weight\n",
      "backbone.body.layer3.1.bn3.bias\n",
      "backbone.body.layer3.1.bn3.running_mean\n",
      "backbone.body.layer3.1.bn3.running_var\n",
      "backbone.body.layer3.2.conv1.weight\n",
      "backbone.body.layer3.2.bn1.weight\n",
      "backbone.body.layer3.2.bn1.bias\n",
      "backbone.body.layer3.2.bn1.running_mean\n",
      "backbone.body.layer3.2.bn1.running_var\n",
      "backbone.body.layer3.2.conv2.weight\n",
      "backbone.body.layer3.2.bn2.weight\n",
      "backbone.body.layer3.2.bn2.bias\n",
      "backbone.body.layer3.2.bn2.running_mean\n",
      "backbone.body.layer3.2.bn2.running_var\n",
      "backbone.body.layer3.2.conv3.weight\n",
      "backbone.body.layer3.2.bn3.weight\n",
      "backbone.body.layer3.2.bn3.bias\n",
      "backbone.body.layer3.2.bn3.running_mean\n",
      "backbone.body.layer3.2.bn3.running_var\n",
      "backbone.body.layer3.3.conv1.weight\n",
      "backbone.body.layer3.3.bn1.weight\n",
      "backbone.body.layer3.3.bn1.bias\n",
      "backbone.body.layer3.3.bn1.running_mean\n",
      "backbone.body.layer3.3.bn1.running_var\n",
      "backbone.body.layer3.3.conv2.weight\n",
      "backbone.body.layer3.3.bn2.weight\n",
      "backbone.body.layer3.3.bn2.bias\n",
      "backbone.body.layer3.3.bn2.running_mean\n",
      "backbone.body.layer3.3.bn2.running_var\n",
      "backbone.body.layer3.3.conv3.weight\n",
      "backbone.body.layer3.3.bn3.weight\n",
      "backbone.body.layer3.3.bn3.bias\n",
      "backbone.body.layer3.3.bn3.running_mean\n",
      "backbone.body.layer3.3.bn3.running_var\n",
      "backbone.body.layer3.4.conv1.weight\n",
      "backbone.body.layer3.4.bn1.weight\n",
      "backbone.body.layer3.4.bn1.bias\n",
      "backbone.body.layer3.4.bn1.running_mean\n",
      "backbone.body.layer3.4.bn1.running_var\n",
      "backbone.body.layer3.4.conv2.weight\n",
      "backbone.body.layer3.4.bn2.weight\n",
      "backbone.body.layer3.4.bn2.bias\n",
      "backbone.body.layer3.4.bn2.running_mean\n",
      "backbone.body.layer3.4.bn2.running_var\n",
      "backbone.body.layer3.4.conv3.weight\n",
      "backbone.body.layer3.4.bn3.weight\n",
      "backbone.body.layer3.4.bn3.bias\n",
      "backbone.body.layer3.4.bn3.running_mean\n",
      "backbone.body.layer3.4.bn3.running_var\n",
      "backbone.body.layer3.5.conv1.weight\n",
      "backbone.body.layer3.5.bn1.weight\n",
      "backbone.body.layer3.5.bn1.bias\n",
      "backbone.body.layer3.5.bn1.running_mean\n",
      "backbone.body.layer3.5.bn1.running_var\n",
      "backbone.body.layer3.5.conv2.weight\n",
      "backbone.body.layer3.5.bn2.weight\n",
      "backbone.body.layer3.5.bn2.bias\n",
      "backbone.body.layer3.5.bn2.running_mean\n",
      "backbone.body.layer3.5.bn2.running_var\n",
      "backbone.body.layer3.5.conv3.weight\n",
      "backbone.body.layer3.5.bn3.weight\n",
      "backbone.body.layer3.5.bn3.bias\n",
      "backbone.body.layer3.5.bn3.running_mean\n",
      "backbone.body.layer3.5.bn3.running_var\n",
      "backbone.body.layer4.0.conv1.weight\n",
      "backbone.body.layer4.0.bn1.weight\n",
      "backbone.body.layer4.0.bn1.bias\n",
      "backbone.body.layer4.0.bn1.running_mean\n",
      "backbone.body.layer4.0.bn1.running_var\n",
      "backbone.body.layer4.0.conv2.weight\n",
      "backbone.body.layer4.0.bn2.weight\n",
      "backbone.body.layer4.0.bn2.bias\n",
      "backbone.body.layer4.0.bn2.running_mean\n",
      "backbone.body.layer4.0.bn2.running_var\n",
      "backbone.body.layer4.0.conv3.weight\n",
      "backbone.body.layer4.0.bn3.weight\n",
      "backbone.body.layer4.0.bn3.bias\n",
      "backbone.body.layer4.0.bn3.running_mean\n",
      "backbone.body.layer4.0.bn3.running_var\n",
      "backbone.body.layer4.0.downsample.0.weight\n",
      "backbone.body.layer4.0.downsample.1.weight\n",
      "backbone.body.layer4.0.downsample.1.bias\n",
      "backbone.body.layer4.0.downsample.1.running_mean\n",
      "backbone.body.layer4.0.downsample.1.running_var\n",
      "backbone.body.layer4.1.conv1.weight\n",
      "backbone.body.layer4.1.bn1.weight\n",
      "backbone.body.layer4.1.bn1.bias\n",
      "backbone.body.layer4.1.bn1.running_mean\n",
      "backbone.body.layer4.1.bn1.running_var\n",
      "backbone.body.layer4.1.conv2.weight\n",
      "backbone.body.layer4.1.bn2.weight\n",
      "backbone.body.layer4.1.bn2.bias\n",
      "backbone.body.layer4.1.bn2.running_mean\n",
      "backbone.body.layer4.1.bn2.running_var\n",
      "backbone.body.layer4.1.conv3.weight\n",
      "backbone.body.layer4.1.bn3.weight\n",
      "backbone.body.layer4.1.bn3.bias\n",
      "backbone.body.layer4.1.bn3.running_mean\n",
      "backbone.body.layer4.1.bn3.running_var\n",
      "backbone.body.layer4.2.conv1.weight\n",
      "backbone.body.layer4.2.bn1.weight\n",
      "backbone.body.layer4.2.bn1.bias\n",
      "backbone.body.layer4.2.bn1.running_mean\n",
      "backbone.body.layer4.2.bn1.running_var\n",
      "backbone.body.layer4.2.conv2.weight\n",
      "backbone.body.layer4.2.bn2.weight\n",
      "backbone.body.layer4.2.bn2.bias\n",
      "backbone.body.layer4.2.bn2.running_mean\n",
      "backbone.body.layer4.2.bn2.running_var\n",
      "backbone.body.layer4.2.conv3.weight\n",
      "backbone.body.layer4.2.bn3.weight\n",
      "backbone.body.layer4.2.bn3.bias\n",
      "backbone.body.layer4.2.bn3.running_mean\n",
      "backbone.body.layer4.2.bn3.running_var\n",
      "backbone.fpn.inner_blocks.0.weight\n",
      "backbone.fpn.inner_blocks.0.bias\n",
      "backbone.fpn.inner_blocks.1.weight\n",
      "backbone.fpn.inner_blocks.1.bias\n",
      "backbone.fpn.inner_blocks.2.weight\n",
      "backbone.fpn.inner_blocks.2.bias\n",
      "backbone.fpn.inner_blocks.3.weight\n",
      "backbone.fpn.inner_blocks.3.bias\n",
      "backbone.fpn.layer_blocks.0.weight\n",
      "backbone.fpn.layer_blocks.0.bias\n",
      "backbone.fpn.layer_blocks.1.weight\n",
      "backbone.fpn.layer_blocks.1.bias\n",
      "backbone.fpn.layer_blocks.2.weight\n",
      "backbone.fpn.layer_blocks.2.bias\n",
      "backbone.fpn.layer_blocks.3.weight\n",
      "backbone.fpn.layer_blocks.3.bias\n",
      "rpn.head.conv.weight not a backbone\n",
      "rpn.head.conv.bias not a backbone\n",
      "rpn.head.cls_logits.weight not a backbone\n",
      "rpn.head.cls_logits.bias not a backbone\n",
      "rpn.head.bbox_pred.weight not a backbone\n",
      "rpn.head.bbox_pred.bias not a backbone\n",
      "roi_heads.box_head.fc6.weight not a backbone\n",
      "roi_heads.box_head.fc6.bias not a backbone\n",
      "roi_heads.box_head.fc7.weight not a backbone\n",
      "roi_heads.box_head.fc7.bias not a backbone\n",
      "roi_heads.box_predictor.cls_score.weight not a backbone\n",
      "roi_heads.box_predictor.cls_score.bias not a backbone\n",
      "roi_heads.box_predictor.bbox_pred.weight not a backbone\n",
      "roi_heads.box_predictor.bbox_pred.bias not a backbone\n",
      "roi_heads.mask_head.mask_fcn1.weight not a backbone\n",
      "roi_heads.mask_head.mask_fcn1.bias not a backbone\n",
      "roi_heads.mask_head.mask_fcn2.weight not a backbone\n",
      "roi_heads.mask_head.mask_fcn2.bias not a backbone\n",
      "roi_heads.mask_head.mask_fcn3.weight not a backbone\n",
      "roi_heads.mask_head.mask_fcn3.bias not a backbone\n",
      "roi_heads.mask_head.mask_fcn4.weight not a backbone\n",
      "roi_heads.mask_head.mask_fcn4.bias not a backbone\n",
      "roi_heads.mask_predictor.conv5_mask.weight not a backbone\n",
      "roi_heads.mask_predictor.conv5_mask.bias not a backbone\n",
      "roi_heads.mask_predictor.mask_fcn_logits.weight not a backbone\n",
      "roi_heads.mask_predictor.mask_fcn_logits.bias not a backbone\n"
     ]
    }
   ],
   "source": [
    "################### MASK R-CNN MODEL ################################################\n",
    "maskrcnn_args = {'num_classes':81, 'min_size':512, 'max_size':800}\n",
    "maskrcnn_model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=False,**maskrcnn_args)\n",
    "print(maskrcnn_model)\n",
    "pretrained_weights = torch.load(os.path.join('mscoco', 'maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth'))\n",
    "# # copy only backbone weights\n",
    "for _n, _par in maskrcnn_model.state_dict().items():\n",
    "     if 'backbone' in _n:\n",
    "        print(_n)\n",
    "        _par.requires_grad = False\n",
    "        _par.copy_(pretrained_weights[_n])\n",
    "        _par.requires_grad = True\n",
    "     else:\n",
    "        print(_n, \"not a backbone\")\n",
    "\n",
    "if device == torch.device('cuda'):\n",
    "   maskrcnn_model = maskrcnn_model.to(device)\n",
    "\n",
    "maskrcnn_model.train()\n",
    "\n",
    "maskrcnn_optimizer_pars = {'lr':1e-5}\n",
    "maskrcnn_optimizer = optim.Adam(list(maskrcnn_model.parameters()),**maskrcnn_optimizer_pars)\n",
    "\n",
    "total_epochs = 5\n",
    "\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 0 = 0.878\n",
      "Loss in epoch 1 = 0.607\n",
      "Loss in epoch 2 = 0.526\n",
      "Loss in epoch 3 = 0.477\n",
      "Loss in epoch 4 = 0.434\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for e in range(total_epochs):\n",
    "    epoch_loss = 0    \n",
    "    for id, b in enumerate(coco_dataloader):\n",
    "        maskrcnn_optimizer.zero_grad()\n",
    "        X,y = b\n",
    "        if device==torch.device('cuda'):\n",
    "            X, y['labels'], y['boxes'], y['masks'] = X.to(device), y['labels'].to(device), y['boxes'].to(device), y['masks'].to(device)\n",
    "        images = [im for im in X]\n",
    "        targets = []\n",
    "        lab={}\n",
    "        # THIS IS IMPORTANT!!!!!\n",
    "        # get rid of the first dimension (batch)\n",
    "        # IF you have >1 images, make another loop\n",
    "        # REPEAT: DO NOT USE BATCH DIMENSION \n",
    "        # Pytorch is sensitive to formats. Labels must be int64, bboxes float32, masks uint8\n",
    "        lab['boxes'] = y['boxes'].squeeze_(0)\n",
    "        lab['labels'] = y['labels'].squeeze_(0)\n",
    "        lab['masks'] = y['masks'].squeeze_(0)\n",
    "        targets.append(lab)\n",
    "        # avoid empty objects\n",
    "        if len(targets)>0:\n",
    "           loss = maskrcnn_model(images, targets)\n",
    "           total_loss = 0\n",
    "           for k in loss.keys():\n",
    "               total_loss += loss[k]\n",
    "           epoch_loss += total_loss.item()\n",
    "           total_loss.backward()        \n",
    "           maskrcnn_optimizer.step()\n",
    "    epoch_loss = epoch_loss/len(coco_dataloader)\n",
    "    print(\"Loss in epoch {0:d} = {1:.3f}\".format(e, epoch_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrcnn_model.eval()\n",
    "torch.save(maskrcnn_model, \"maskrcnn_mscoco.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
